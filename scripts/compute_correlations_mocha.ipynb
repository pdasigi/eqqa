{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf925ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "DIV_CMAP = sns.diverging_palette(220, 0, as_cmap=True) # DIVERGENT COLOR MAP\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "METRICS_DIR = \"../outputs/proxy_metrics_20220426\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d853a530",
   "metadata": {},
   "source": [
    "## Compute correlations for individual metrics in DEV set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25888666",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"dev\"\n",
    "DATASET = \"all_datasets\"\n",
    "TARGET_COL = \"human_correctness\"\n",
    "\n",
    "DEV_FILEPATH = f\"{METRICS_DIR}/{SPLIT}_{DATASET}_metrics.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686fc934",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = pd.read_csv(DEV_FILEPATH, index_col=0)\n",
    "print(\"Read dataset with\", len(dev_df), \"examples from\", DEV_FILEPATH)\n",
    "print(\"Data file contains data for:\", dev_df.dataset.unique())\n",
    "dev_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bfde91",
   "metadata": {},
   "source": [
    "### Compute Pearson and Spearman Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad57bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_correlations(df, dataset=None, metric_cols=None, target_col=TARGET_COL):\n",
    "    from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "    if dataset is not None:\n",
    "        df = df[df[\"dataset\"] == dataset].copy()\n",
    "    \n",
    "    if metric_cols is None:\n",
    "        metric_cols = df.select_dtypes(\"number\").columns\n",
    "    \n",
    "    results = {}\n",
    "    for metric_col in metric_cols:\n",
    "        metric_corrs = {}\n",
    "        \n",
    "        correctness = df[target_col]\n",
    "        metric_values = df[metric_col]\n",
    "        \n",
    "        pearson_val, p_value = pearsonr(correctness, metric_values)\n",
    "        metric_corrs[\"pearson\"] = pearson_val\n",
    "        metric_corrs[\"pearson_pval\"] = p_value\n",
    "\n",
    "        spearman_val, p_value = spearmanr(correctness, metric_values)\n",
    "        metric_corrs[\"spearman\"] = spearman_val\n",
    "        metric_corrs[\"spearman_pval\"] = p_value\n",
    "        \n",
    "        # metric_corrs[\"dataset\"] = dataset\n",
    "        metric_corrs[\"n\"] = len(df)\n",
    "        results[metric_col] = metric_corrs\n",
    "        \n",
    "    return results\n",
    "\n",
    "\n",
    "def get_all_correlations(df):\n",
    "    unique_datasets = sorted(df.dataset.unique())\n",
    "\n",
    "    correlations = {\"all_datasets\": collect_correlations(df)}\n",
    "    correlations.update({\n",
    "        d: collect_correlations(df, dataset=d) for d in unique_datasets\n",
    "    })\n",
    "    \n",
    "    return correlations\n",
    "\n",
    "\n",
    "# Sanity check (:\n",
    "collect_correlations(dev_df);\n",
    "get_all_correlations(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41188267",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_correlations = get_all_correlations(dev_df)\n",
    "\n",
    "dev_corr_dfs = []\n",
    "for dataset_name, correlations in dev_correlations.items():\n",
    "    _df = pd.DataFrame.from_dict(correlations).T \n",
    "    dev_corr_dfs.append(_df)\n",
    "\n",
    "dev_corr_dfs = pd.concat(dev_corr_dfs, keys=list(dev_correlations.keys()), axis=1)\n",
    "dev_corr_dfs.to_csv(f\"{METRICS_DIR}/dev_individual_correlations.csv\")\n",
    "dev_corr_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c997d49",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_correlation_heatmaps(data_correlations: dict):\n",
    "    for dataset, correlations in data_correlations.items():\n",
    "        df = pd.DataFrame.from_dict(correlations).T    \n",
    "        df = df.drop([\"pearson_pval\", \"spearman_pval\", \"n\"], axis=1)\n",
    "\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.title(f\"{METRICS_DIR} - {SPLIT} - {dataset}\")\n",
    "        sns.heatmap(df, vmin=-1, vmax=1, cmap=DIV_CMAP, annot=True)\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "plot_correlation_heatmaps(dev_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee9152",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_col_distribution(df, col, split, figsize=(5, 3), **kwargs):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title(f\"{METRICS_DIR} - {split} - all_datasets\")\n",
    "    sns.histplot(data=df, x=col, **kwargs)\n",
    "    plt.show()\n",
    "\n",
    "    for dataset in sorted(df.dataset.unique()):\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.title(f\"{METRICS_DIR} - {split} - {dataset}\")\n",
    "        sns.histplot(data=df[df[\"dataset\"] == dataset], x=col, **kwargs)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "plot_col_distribution(dev_df, TARGET_COL, split=\"dev\", binrange=(0, 1), bins=20, stat=\"probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d6eeef",
   "metadata": {},
   "source": [
    "## Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81498aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILEPATH = f\"{METRICS_DIR}/train_all_datasets_metrics.csv.gz\"\n",
    "\n",
    "# Read original training set\n",
    "train_df = pd.read_csv(TRAIN_FILEPATH, index_col=0)\n",
    "print(\"Read dataset with\", len(train_df), \"examples from\", TRAIN_FILEPATH)\n",
    "\n",
    "# Define the columns to be all number types except the human correctness\n",
    "METRIC_COLS = train_df.select_dtypes(\"number\").columns\n",
    "features = list(METRIC_COLS[2:])\n",
    "\n",
    "# Target column will be the normalized human correctness\n",
    "target = METRIC_COLS[1]\n",
    "print(\"Target:\", target, \"\\nFeatures:\", features)\n",
    "\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2cf235",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_col_distribution(train_df, target, split=\"train\", binrange=(0, 1), bins=20, stat=\"probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc84eb51",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5329727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "def preprocess(data, scalers = None):\n",
    "    data = data.copy()\n",
    "    \n",
    "    results = {}\n",
    "    if scalers is not None:\n",
    "        results = scalers\n",
    "    \n",
    "    for f in features:\n",
    "        if scalers is None:\n",
    "            scaler = StandardScaler()\n",
    "            data[f] = scaler.fit_transform(data[f].values.reshape(-1, 1))\n",
    "            results[f] = scaler\n",
    "        else:\n",
    "            scaler = results[f]\n",
    "            data[f] = scaler.transform(data[f].values.reshape(-1, 1))\n",
    "            \n",
    "    return data, results\n",
    "\n",
    "\n",
    "def fit_model(data, estimator, dataset=None):\n",
    "\n",
    "    if dataset is not None:\n",
    "        data = data[data[\"dataset\"] == dataset]\n",
    "    \n",
    "    print(\"Considering dataset with\", len(data), \"examples, spanning datasets:\", data.dataset.unique())\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], test_size=0.20, random_state=78452, stratify=data[target])\n",
    "    print(X_train.shape, X_test.shape)\n",
    "    \n",
    "    # Preprocessing data (since LR may be sensitive to it)\n",
    "    X_train_prec, scalers = preprocess(X_train)\n",
    "    X_test_prec, _ = preprocess(X_test, scalers=scalers)\n",
    "\n",
    "    # Create estimator\n",
    "    clf = estimator()\n",
    "    clf.fit(X_train_prec, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    scores = clf.predict(X_test_prec)\n",
    "    results = {\n",
    "        \"mse\": metrics.mean_squared_error(y_test, scores),\n",
    "        \"r2\": metrics.r2_score(y_test, scores),\n",
    "        \"pearson\": pearsonr(scores, y_test)[0],\n",
    "        \"spearman\": spearmanr(scores, y_test),\n",
    "    }\n",
    "    return clf, scalers, results\n",
    "\n",
    "\n",
    "def eval_datasets(model, eval_datasets: dict, scalers: dict):\n",
    "    eval_results = {}\n",
    "    eval_scores = {}\n",
    "    for dataset_name, dataset in eval_datasets.items():\n",
    "        X, y = dataset[features], dataset[target]\n",
    "\n",
    "        X_prec, _ = preprocess(X.copy(), scalers=scalers)\n",
    "\n",
    "        scores = model.predict(X_prec)\n",
    "        eval_results[dataset_name] = {\n",
    "            \"mse\": metrics.mean_squared_error(y, scores),\n",
    "            \"r2\": metrics.r2_score(y, scores),\n",
    "            \"pearson\": pearsonr(scores, y)[0],\n",
    "            \"spearman\": spearmanr(scores, y)[0],\n",
    "        }\n",
    "        eval_scores[dataset_name] = scores\n",
    "        \n",
    "    return eval_results, eval_scores\n",
    "\n",
    "# Sanity check\n",
    "lr, lr_scalers, valid_results = fit_model(train_df, LinearRegression, dataset=\"narrativeqa\")\n",
    "valid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbd5f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Unique datasets\n",
    "unique_datasets = list(train_df.dataset.unique())\n",
    "\n",
    "# Evaluation datasets\n",
    "# includes all_datasets (macro eval), as well as individual datasets\n",
    "dev_orig_datasets = {None: dev_df}\n",
    "dev_orig_datasets.update({dataset: dev_df[dev_df.dataset == dataset] for dataset in unique_datasets})\n",
    "\n",
    "models = {}\n",
    "results_by_dataset = {}\n",
    "for dataset_name in dev_orig_datasets.keys():\n",
    "    print(\"Fitting model using\", \"all\" if dataset_name is None else dataset_name, \"datasets\")\n",
    "    model, model_scalers, valid_results = fit_model(train_df, LinearRegression, dataset=dataset_name)\n",
    "    \n",
    "    models[dataset_name] = model\n",
    "    results, scores = eval_datasets(model, dev_orig_datasets, model_scalers)\n",
    "    \n",
    "    results_by_dataset[dataset_name] = results    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519437f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_results = defaultdict(list)\n",
    "\n",
    "for train_dataset, test_values in results_by_dataset.items():\n",
    "    \n",
    "    for test_dataset, test_results in test_values.items():\n",
    "        table_results[\"train_dataset\"].append(\"all_datasets\" if train_dataset is None else train_dataset)\n",
    "        table_results[\"eval_dataset\"].append(\"all_datasets\" if test_dataset is None else test_dataset)\n",
    "        \n",
    "        for metric, metric_value in test_results.items():\n",
    "            table_results[metric].append(metric_value)\n",
    "            \n",
    "table_results = pd.DataFrame(table_results)\n",
    "table_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87061f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_model_coeffs(train_dataset): \n",
    "    clf = models[train_dataset]\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(f\"Feature importance for train dataset: {train_dataset if train_dataset is not None else 'all_datasets'}\")\n",
    "    sns.barplot(y=features, x=clf.coef_, orient=\"h\")\n",
    "    plt.xlim(-1, 1)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "for train_dataset in models.keys():\n",
    "    plot_model_coeffs(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03327f15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
