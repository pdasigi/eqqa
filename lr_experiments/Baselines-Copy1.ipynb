{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb651c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_datasets import read_json_dataset\n",
    "from dict_utils import unfold_to_list, fold_from_list\n",
    "from pipeline import Pipeline, FewShotPipeline, FineTuningFewShotPipeline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "def add_lerc_preds(data, lerc_preds_dir, split):\n",
    "    lerc_preds = read_json_dataset(lerc_preds_dir, split)\n",
    "        \n",
    "    for dataset, d in lerc_preds.items():\n",
    "        for example_id, score in d.items():\n",
    "            data[dataset][example_id][\"LERC\"] = (score[\"pred_score\"] - 1) / (5-1)\n",
    "            \n",
    "    return data\n",
    "\n",
    "\n",
    "def add_log(data, metrics):\n",
    "    for m in metrics:\n",
    "        data[f\"{m}_log\"] = data[m].apply(lambda s: np.log(s+1e-15)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e6f3239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6 6\n",
      "(31069, 49) (4009, 49) (6321, 49)\n"
     ]
    }
   ],
   "source": [
    "DATASET_DIR = \"../data/lr_experiments\"\n",
    "LERC_PREDS_DIR = f\"{DATASET_DIR}/lerc_preds\"\n",
    "\n",
    "RESULTS_DIR = \"./experiments_20220605/results\"\n",
    "\n",
    "train = read_json_dataset(DATASET_DIR, \"train_metrics\")\n",
    "dev = read_json_dataset(DATASET_DIR, \"dev_metrics\")\n",
    "test = read_json_dataset(DATASET_DIR, \"test_metrics\")\n",
    "print(len(train), len(dev), len(test))\n",
    "\n",
    "add_lerc_preds(train, LERC_PREDS_DIR, \"train\")\n",
    "add_lerc_preds(dev, LERC_PREDS_DIR, \"dev\")\n",
    "add_lerc_preds(test, LERC_PREDS_DIR, \"test\")\n",
    "\n",
    "train_df = pd.DataFrame(unfold_to_list(train, \"dataset\", \"example_id\"))\n",
    "dev_df   = pd.DataFrame(unfold_to_list(dev, \"dataset\", \"example_id\"))\n",
    "test_df  = pd.DataFrame(unfold_to_list(test, \"dataset\", \"example_id\"))\n",
    "print(train_df.shape, dev_df.shape, test_df.shape)\n",
    "\n",
    "train_df[\"score_scaled\"] = train_df.score.apply(lambda s: (s-1)/(5-1))\n",
    "dev_df[\"score_scaled\"] = dev_df.score.apply(lambda s: (s-1)/(5-1))\n",
    "test_df[\"score_scaled\"] = test_df.score.apply(lambda s: (s-1)/(5-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26564e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = list(train.keys())\n",
    "\n",
    "METRICS = [\n",
    "    # Bleu\n",
    "    'bleu1', 'bleu2', 'bleu3', 'bleu4', \n",
    "    # 'hf_bleu1', 'hf_bleu2', 'hf_bleu3', 'hf_bleu4', \n",
    "    'rougeL', \n",
    "    # 'hf_rougeL', 'hf_rougeLsum',\n",
    "    'hf_rouge1', 'hf_rouge2',\n",
    "    'meteor',\n",
    "    'recall', 'precision', 'f1_score',\n",
    "    'sari_context', 'sari_question',\n",
    "    # Token overlap when 1st error occurred\n",
    "    'precision_at_err1', 'recall_at_err1',\n",
    "    # Confusion matrix\n",
    "    'tp', 'fn', 'fp',\n",
    "    # Edit scores ------\n",
    "    'char_edit_score',\n",
    "    'word_edit_score',\n",
    "    # Learned metrics -------\n",
    "    'bertscore', \n",
    "    'bleurt',\n",
    "    # \n",
    "    \"LERC\",\n",
    "    # Input statistics ------\n",
    "    'candidatelength_word',\n",
    "    'candidatelength_char',\n",
    "    'candidatenunique_words',\n",
    "    'referencelength_word',\n",
    "    'referencelength_char',\n",
    "    'referencenunique_words',\n",
    "    'contextlength_word',\n",
    "    'contextlength_char',\n",
    "    'contextnunique_words',\n",
    "    'questionlength_word',\n",
    "    'questionlength_char',\n",
    "    'questionnunique_words',\n",
    "]\n",
    "\n",
    "TARGET = \"score_scaled\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f93496",
   "metadata": {},
   "source": [
    "**Validate numbers reported in original MOCHA paper**\n",
    "\n",
    "Most of the values are close to the numbers reported in the paper. The ones that are not, are consistently higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ce19408",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- DEV SET ----\n",
      "cosmosqa bleu1 0.66\n",
      "cosmosqa meteor 0.697\n",
      "cosmosqa rougeL 0.702\n",
      "cosmosqa bert-score 0.805\n",
      "\n",
      "TEST SET\n",
      "cosmosqa bleu1 0.671\n",
      "cosmosqa meteor 0.712\n",
      "cosmosqa rougeL 0.701\n",
      "cosmosqa bert-score 0.78\n",
      "\n",
      "\n",
      "---- DEV SET ----\n",
      "drop bleu1 0.409\n",
      "drop meteor 0.664\n",
      "drop rougeL 0.48\n",
      "drop bert-score 0.174\n",
      "\n",
      "TEST SET\n",
      "drop bleu1 0.388\n",
      "drop meteor 0.568\n",
      "drop rougeL 0.366\n",
      "drop bert-score 0.329\n",
      "\n",
      "\n",
      "---- DEV SET ----\n",
      "mcscript bleu1 0.182\n",
      "mcscript meteor 0.461\n",
      "mcscript rougeL 0.225\n",
      "mcscript bert-score 0.173\n",
      "\n",
      "TEST SET\n",
      "mcscript bleu1 0.261\n",
      "mcscript meteor 0.503\n",
      "mcscript rougeL 0.297\n",
      "mcscript bert-score 0.195\n",
      "\n",
      "\n",
      "---- DEV SET ----\n",
      "narrativeqa bleu1 0.403\n",
      "narrativeqa meteor 0.606\n",
      "narrativeqa rougeL 0.434\n",
      "narrativeqa bert-score 0.419\n",
      "\n",
      "TEST SET\n",
      "narrativeqa bleu1 0.472\n",
      "narrativeqa meteor 0.616\n",
      "narrativeqa rougeL 0.496\n",
      "narrativeqa bert-score 0.535\n",
      "\n",
      "\n",
      "---- DEV SET ----\n",
      "quoref bleu1 0.675\n",
      "quoref meteor 0.729\n",
      "quoref rougeL 0.713\n",
      "quoref bert-score 0.208\n",
      "\n",
      "TEST SET\n",
      "quoref bleu1 0.578\n",
      "quoref meteor 0.716\n",
      "quoref rougeL 0.604\n",
      "quoref bert-score 0.287\n",
      "\n",
      "\n",
      "---- DEV SET ----\n",
      "socialiqa bleu1 0.595\n",
      "socialiqa meteor 0.644\n",
      "socialiqa rougeL 0.599\n",
      "socialiqa bert-score 0.605\n",
      "\n",
      "TEST SET\n",
      "socialiqa bleu1 0.549\n",
      "socialiqa meteor 0.638\n",
      "socialiqa rougeL 0.558\n",
      "socialiqa bert-score 0.585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    print(); print(\"---- DEV SET ----\")\n",
    "    _df = dev_df[dev_df.dataset == dataset]\n",
    "    print(dataset, \"bleu1\", round(pearsonr(_df[\"score_scaled\"], _df[\"bleu1\"])[0], 3))\n",
    "    print(dataset, \"meteor\", round(pearsonr(_df[\"score_scaled\"], _df[\"meteor\"])[0], 3))\n",
    "    print(dataset, \"rougeL\", round(pearsonr(_df[\"score_scaled\"], _df[\"rougeL\"])[0], 3))\n",
    "    print(dataset, \"bert-score\", round(pearsonr(_df[\"score_scaled\"], _df[\"bertscore\"])[0], 3))\n",
    "    print()\n",
    "    \n",
    "    print(\"TEST SET\")\n",
    "    _df = test_df[test_df.dataset == dataset]\n",
    "    print(dataset, \"bleu1\", round(pearsonr(_df[\"score_scaled\"], _df[\"bleu1\"])[0], 3))\n",
    "    print(dataset, \"meteor\", round(pearsonr(_df[\"score_scaled\"], _df[\"meteor\"])[0], 3))\n",
    "    print(dataset, \"rougeL\", round(pearsonr(_df[\"score_scaled\"], _df[\"rougeL\"])[0], 3))\n",
    "    print(dataset, \"bert-score\", round(pearsonr(_df[\"score_scaled\"], _df[\"bertscore\"])[0], 3))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8936786",
   "metadata": {},
   "source": [
    "# Regression Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ac8b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(df, dataset = None, col=\"dataset\"):\n",
    "    return df[df[col] == dataset].copy() if dataset else df\n",
    "    \n",
    "def get_all_datasets(df, datasets, include_all=True):\n",
    "    result = {} if not include_all else {\"all\": df.copy()}\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        result.update({dataset: get_subset(df, dataset)})\n",
    "        \n",
    "    return result\n",
    "\n",
    "def get_loov_datasets(df, datasets):\n",
    "    result = {}\n",
    "\n",
    "    for dataset in datasets:\n",
    "        loo_datasets = [get_subset(df, d) for d in datasets if d != dataset]\n",
    "        loo_dataset = pd.concat(loo_datasets)\n",
    "        \n",
    "        result.update({f\"except_{dataset}\": loo_dataset})\n",
    "        \n",
    "    return result\n",
    "\n",
    "TRAIN_DATASETS = get_all_datasets(train_df, DATASETS)\n",
    "DEV_DATASETS   = get_all_datasets(dev_df, DATASETS)\n",
    "TEST_DATASETS  = get_all_datasets(test_df, DATASETS)\n",
    "\n",
    "TRAIN_LOO_DATASETS = get_loov_datasets(train_df, DATASETS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6344c8e8",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "066d2363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(\n",
    "        model_class,\n",
    "        model_hparams,\n",
    "        features,\n",
    "        target,\n",
    "        train_datasets,\n",
    "        split_frac=None,\n",
    "        with_std=True,\n",
    "        with_pca=False,\n",
    "        seed=817237,\n",
    "        pipeline_class=Pipeline,\n",
    "    ) -> dict:\n",
    "    pipelines = {}\n",
    "    \n",
    "    for train_name, train_data in train_datasets.items():\n",
    "        pipeline = pipeline_class(model_class, model_hparams, train_name, features, target, seed=seed)\n",
    "        pipeline.load_data(train_data)\n",
    "        if split_frac and isinstance(split_frac, float):\n",
    "            pipeline.split(holdout_fraction=split_frac)\n",
    "\n",
    "        pipeline.preprocess(with_std=with_std, with_pca=with_pca)\n",
    "        pipeline.fit()\n",
    "        pipelines[train_name] = pipeline\n",
    "\n",
    "    return pipelines\n",
    "\n",
    "\n",
    "def evaluate(pipelines, eval_datasets):\n",
    "    results = []\n",
    "    for train_name, pipeline in pipelines.items():\n",
    "        result = pipeline.evaluate_multiple(eval_datasets)\n",
    "        results.extend(result)\n",
    "    return results\n",
    "\n",
    "def evaluate_loo(pipelines, eval_datasets):\n",
    "    results = []\n",
    "    for train_name, pipeline in pipelines.items():\n",
    "        loo_dataset = train_name.rpartition(\"_\")[-1]\n",
    "        result = pipeline.evaluate_multiple({loo_dataset: eval_datasets[loo_dataset]})\n",
    "        results.extend(result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f30803",
   "metadata": {},
   "source": [
    "## Individual metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "579ca0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndividualMetric:\n",
    "    def __init__(self, feature=None):\n",
    "        self.feature = feature\n",
    "                \n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.feature is None:\n",
    "            raise RuntimeError(\"No feature specified\")\n",
    "\n",
    "        y_pred = X[self.feature]\n",
    "        \n",
    "        assert len(y_pred) == X.shape[0]\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0ce5628",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>r2</th>\n",
       "      <th>pearson</th>\n",
       "      <th>spearman</th>\n",
       "      <th>features</th>\n",
       "      <th>target</th>\n",
       "      <th>model_classpath</th>\n",
       "      <th>model_hparams</th>\n",
       "      <th>trained_on</th>\n",
       "      <th>evaluated_on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054807</td>\n",
       "      <td>0.609562</td>\n",
       "      <td>0.810055</td>\n",
       "      <td>0.784910</td>\n",
       "      <td>[LERC]</td>\n",
       "      <td>score_scaled</td>\n",
       "      <td>LERC</td>\n",
       "      <td>{'feature': 'LERC'}</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.052269</td>\n",
       "      <td>0.652098</td>\n",
       "      <td>0.859841</td>\n",
       "      <td>0.820316</td>\n",
       "      <td>[LERC]</td>\n",
       "      <td>score_scaled</td>\n",
       "      <td>LERC</td>\n",
       "      <td>{'feature': 'LERC'}</td>\n",
       "      <td>all</td>\n",
       "      <td>cosmosqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.049659</td>\n",
       "      <td>0.630796</td>\n",
       "      <td>0.816460</td>\n",
       "      <td>0.739219</td>\n",
       "      <td>[LERC]</td>\n",
       "      <td>score_scaled</td>\n",
       "      <td>LERC</td>\n",
       "      <td>{'feature': 'LERC'}</td>\n",
       "      <td>all</td>\n",
       "      <td>drop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.054287</td>\n",
       "      <td>0.629135</td>\n",
       "      <td>0.812387</td>\n",
       "      <td>0.786814</td>\n",
       "      <td>[LERC]</td>\n",
       "      <td>score_scaled</td>\n",
       "      <td>LERC</td>\n",
       "      <td>{'feature': 'LERC'}</td>\n",
       "      <td>all</td>\n",
       "      <td>mcscript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059730</td>\n",
       "      <td>0.601472</td>\n",
       "      <td>0.793851</td>\n",
       "      <td>0.786998</td>\n",
       "      <td>[LERC]</td>\n",
       "      <td>score_scaled</td>\n",
       "      <td>LERC</td>\n",
       "      <td>{'feature': 'LERC'}</td>\n",
       "      <td>all</td>\n",
       "      <td>narrativeqa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mse        r2   pearson  spearman features        target  \\\n",
       "0  0.054807  0.609562  0.810055  0.784910   [LERC]  score_scaled   \n",
       "1  0.052269  0.652098  0.859841  0.820316   [LERC]  score_scaled   \n",
       "2  0.049659  0.630796  0.816460  0.739219   [LERC]  score_scaled   \n",
       "3  0.054287  0.629135  0.812387  0.786814   [LERC]  score_scaled   \n",
       "4  0.059730  0.601472  0.793851  0.786998   [LERC]  score_scaled   \n",
       "\n",
       "  model_classpath        model_hparams trained_on evaluated_on  \n",
       "0            LERC  {'feature': 'LERC'}        all          all  \n",
       "1            LERC  {'feature': 'LERC'}        all     cosmosqa  \n",
       "2            LERC  {'feature': 'LERC'}        all         drop  \n",
       "3            LERC  {'feature': 'LERC'}        all     mcscript  \n",
       "4            LERC  {'feature': 'LERC'}        all  narrativeqa  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual_results = []\n",
    "for metric in [\"LERC\"] + METRICS: \n",
    "    ps = fit(IndividualMetric, {\"feature\": metric}, [metric], TARGET, {\"all\": TRAIN_DATASETS[\"all\"]}, with_pca=False, with_std=False)\n",
    "    results = evaluate(ps, DEV_DATASETS)\n",
    "    for r in results:\n",
    "        r[\"model_classpath\"] = metric\n",
    "    \n",
    "    individual_results.extend(results)\n",
    "\n",
    "individual_results = pd.DataFrame(individual_results)\n",
    "individual_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fbae8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_results.to_csv(f\"{RESULTS_DIR}/baselines/individual_metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f3759",
   "metadata": {},
   "source": [
    "### Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66fc8f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageBaseline:\n",
    "    def __init__(self, features=None, subset=None):\n",
    "        if features is None or subset is None:\n",
    "            self.features = None\n",
    "            self.subset = None\n",
    "            self.subset_feat_ids = None\n",
    "        else:\n",
    "            self.features = features\n",
    "            self.subset = subset        \n",
    "            self.subset_feat_ids = [i for i, f in enumerate(features) if f in subset]\n",
    "                \n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.features is not None:\n",
    "            X = X[:, self.subset_feat_ids]\n",
    "        else:\n",
    "            print(\"Since no features were specified, using all input to make prediction\")\n",
    "\n",
    "        y_pred = np.mean(X, axis=1)\n",
    "        assert len(y_pred) == X.shape[0]\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf4e7509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bleu1',\n",
       " 'bleu2',\n",
       " 'bleu3',\n",
       " 'bleu4',\n",
       " 'rougeL',\n",
       " 'hf_rouge1',\n",
       " 'hf_rouge2',\n",
       " 'meteor',\n",
       " 'recall',\n",
       " 'precision',\n",
       " 'f1_score',\n",
       " 'sari_context',\n",
       " 'sari_question',\n",
       " 'precision_at_err1',\n",
       " 'recall_at_err1',\n",
       " 'tp',\n",
       " 'fn',\n",
       " 'fp',\n",
       " 'char_edit_score',\n",
       " 'word_edit_score',\n",
       " 'bertscore',\n",
       " 'bleurt',\n",
       " 'LERC',\n",
       " 'candidatelength_word',\n",
       " 'candidatelength_char',\n",
       " 'candidatenunique_words',\n",
       " 'referencelength_word',\n",
       " 'referencelength_char',\n",
       " 'referencenunique_words',\n",
       " 'contextlength_word',\n",
       " 'contextlength_char',\n",
       " 'contextnunique_words',\n",
       " 'questionlength_word',\n",
       " 'questionlength_char',\n",
       " 'questionnunique_words']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32b19646",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL Baseline\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'cosmosqa': ['cosmosqa']\n",
      "Loading dataset 'drop': ['drop']\n",
      "Loading dataset 'mcscript': ['mcscript']\n",
      "Loading dataset 'narrativeqa': ['narrativeqa']\n",
      "Loading dataset 'quoref': ['quoref']\n",
      "Loading dataset 'socialiqa': ['socialiqa']\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'cosmosqa': ['cosmosqa']\n",
      "Loading dataset 'drop': ['drop']\n",
      "Loading dataset 'mcscript': ['mcscript']\n",
      "Loading dataset 'narrativeqa': ['narrativeqa']\n",
      "Loading dataset 'quoref': ['quoref']\n",
      "Loading dataset 'socialiqa': ['socialiqa']\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'cosmosqa': ['cosmosqa']\n",
      "Loading dataset 'drop': ['drop']\n",
      "Loading dataset 'mcscript': ['mcscript']\n",
      "Loading dataset 'narrativeqa': ['narrativeqa']\n",
      "Loading dataset 'quoref': ['quoref']\n",
      "Loading dataset 'socialiqa': ['socialiqa']\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'cosmosqa': ['cosmosqa']\n",
      "Loading dataset 'drop': ['drop']\n",
      "Loading dataset 'mcscript': ['mcscript']\n",
      "Loading dataset 'narrativeqa': ['narrativeqa']\n",
      "Loading dataset 'quoref': ['quoref']\n",
      "Loading dataset 'socialiqa': ['socialiqa']\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since no features were specified, using all input to make prediction\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'cosmosqa': ['cosmosqa']\n",
      "Loading dataset 'drop': ['drop']\n",
      "Loading dataset 'mcscript': ['mcscript']\n",
      "Loading dataset 'narrativeqa': ['narrativeqa']\n",
      "Loading dataset 'quoref': ['quoref']\n",
      "Loading dataset 'socialiqa': ['socialiqa']\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'cosmosqa': ['cosmosqa']\n",
      "Loading dataset 'drop': ['drop']\n",
      "Loading dataset 'mcscript': ['mcscript']\n",
      "Loading dataset 'narrativeqa': ['narrativeqa']\n",
      "Loading dataset 'quoref': ['quoref']\n",
      "Loading dataset 'socialiqa': ['socialiqa']\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Loading dataset 'all': ['cosmosqa' 'drop' 'mcscript' 'narrativeqa' 'quoref' 'socialiqa']\n",
      "Loading dataset 'cosmosqa': ['cosmosqa']\n",
      "Loading dataset 'drop': ['drop']\n",
      "Loading dataset 'mcscript': ['mcscript']\n",
      "Loading dataset 'narrativeqa': ['narrativeqa']\n",
      "Loading dataset 'quoref': ['quoref']\n",
      "Loading dataset 'socialiqa': ['socialiqa']\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n",
      "Since no features were specified, using all input to make prediction\n"
     ]
    }
   ],
   "source": [
    "top3_features  = {\n",
    "    \"cosmosqa\": [\"bleurt\", \"bertscore\", \"meteor\"],\n",
    "    \"drop\": [\"hf_rouge1\", \"meteor\", \"f1_score\"],\n",
    "    \"mcscript\": [\"bleurt\", \"meteor\", \"hf_rouge1\"],\n",
    "    \"narrativeqa\": [\"bleurt\", \"bertscore\", \"meteor\"],\n",
    "    \"quoref\": [\"hf_rouge1\", \"meteor\", \"bleurt\"],\n",
    "    \"socialiqa\": [\"bleurt\", \"meteor\", \"precision\"],\n",
    "}\n",
    "\n",
    "ad_avg_results = []\n",
    "# All datasets experiment\n",
    "print(\"ALL Baseline\")\n",
    "ad_avg_pipelines = fit(AverageBaseline, {}, METRICS, TARGET, TRAIN_DATASETS)\n",
    "ad_avg_results.append(evaluate(ad_avg_pipelines, DEV_DATASETS))\n",
    "\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    features = top3_features[dataset]\n",
    "    \n",
    "    ad_avg_pipelines = fit(AverageBaseline, {}, features, TARGET, TRAIN_DATASETS)\n",
    "    ad_avg_results.append(evaluate(ad_avg_pipelines, DEV_DATASETS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536539a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f8fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Stronger avgs\n",
    "# (per dataset)\n",
    "# Learn avg in training and predict that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91694d9",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf5de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"LERC\" in METRICS:\n",
    "    name = \"_w_lerc\"\n",
    "else:\n",
    "    name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All datasets experiment\n",
    "ad_lr_pipelines = fit(LinearRegression, {}, METRICS, TARGET, TRAIN_DATASETS)\n",
    "ad_lr_results = evaluate(ad_lr_pipelines, DEV_DATASETS)\n",
    "ad_lr_results = pd.DataFrame(ad_lr_results)\n",
    "ad_lr_results.to_csv(f\"results/ad_lr{name}.csv\")\n",
    "\n",
    "loo_lr_pipelines = fit(LinearRegression, {}, METRICS, TARGET, TRAIN_LOO_DATASETS)\n",
    "loo_lr_results = evaluate(loo_lr_pipelines, DEV_DATASETS)\n",
    "loo_lr_results = pd.DataFrame(loo_lr_results)\n",
    "loo_lr_results.to_csv(f\"results/loo_lr{name}.csv\")\n",
    "\n",
    "# All (baseline) LR results\n",
    "lr_results = pd.concat((ad_lr_results, loo_lr_results)).reset_index(drop=True)\n",
    "# lr_results.to_csv(\"results/lr.csv\")\n",
    "\n",
    "lr_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa1be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in DATASETS:\n",
    "    eval_on_mask = lr_results[\"evaluated_on\"] == dataset\n",
    "    train_on_mask = lr_results[\"trained_on\"] == f\"all\"\n",
    "    print(\"all\", dataset, lr_results.loc[train_on_mask & eval_on_mask, \"pearson\"])\n",
    "    \n",
    "print(\"\\n\", \"#\" * 20)\n",
    "print(\"LOO\")\n",
    "for dataset in DATASETS:\n",
    "    train_on_mask = lr_results[\"trained_on\"] == f\"except_{dataset}\"\n",
    "    print(dataset, \":\", lr_results.loc[train_on_mask, [\"evaluated_on\", \"pearson\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063a3feb",
   "metadata": {},
   "source": [
    "## L1 Regression (Lasso Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1993d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from scipy.stats import expon\n",
    "\n",
    "\n",
    "def get_alpha(args):\n",
    "    return eval(args)[\"alpha\"]\n",
    "\n",
    "\n",
    "def plot_metric_by_alpha(data, metric, **kwargs):\n",
    "    n_plots = data.trained_on.nunique()\n",
    "    n_cols = 3\n",
    "\n",
    "    n_rows = n_plots // n_cols\n",
    "    n_rows += n_plots % n_cols\n",
    "\n",
    "    position = range(1, n_plots+1)\n",
    "\n",
    "    fig = plt.figure(1, figsize=(10, 10), dpi=150)\n",
    "\n",
    "    for k, trained_on in enumerate(data.trained_on.unique()):\n",
    "        d = data[(data[\"trained_on\"] == trained_on)]\n",
    "        ax = fig.add_subplot(n_rows, n_cols, position[k])\n",
    "        sns.lineplot(data=d, x=\"alpha\", y=metric, ax=ax, **kwargs)\n",
    "        ax.set_title(f\"Trained_on={trained_on}\")\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d72601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will perform model selection using L1 regression\n",
    "# since it is known to enforce sparsity of the solution!\n",
    "N_L1_MODELS = 100\n",
    "\n",
    "L1_GRID = {'alpha': expon(loc=0, scale=0.20)}\n",
    "L1_PARAMS = list(ParameterSampler(L1_GRID, n_iter=N_L1_MODELS, random_state=81723))\n",
    "\n",
    "plt.figure(figsize=(5, 3), dpi=150)\n",
    "plt.hist([p[\"alpha\"] for p in L1_PARAMS])\n",
    "plt.title(\"Distribution of the sampled alpha values for Lasso\")\n",
    "plt.savefig(\"results/l1_alphas_dist.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5342754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_pipelines = {}\n",
    "ad_results = []\n",
    "loo_results = []\n",
    "for i, l1_hparams in enumerate(L1_PARAMS):\n",
    "    if l1_hparams[\"alpha\"] > 2:\n",
    "        continue\n",
    "\n",
    "    # All datasets experiment\n",
    "    ad_l1_pipelines = fit(Lasso, l1_hparams, METRICS, TARGET, TRAIN_DATASETS)\n",
    "    ad_l1_results = evaluate(ad_l1_pipelines, DEV_DATASETS)\n",
    "    ad_l1_results = pd.DataFrame(ad_l1_results)\n",
    "    ad_l1_results[\"i\"] = i\n",
    "    ad_results.append(ad_l1_results)\n",
    "\n",
    "    loo_l1_pipelines = fit(Lasso, l1_hparams, METRICS, TARGET, TRAIN_LOO_DATASETS)\n",
    "    # loo_l1_results = evaluate(loo_l1_pipelines, DEV_DATASETS)\n",
    "    loo_l1_results = evaluate_loo(loo_l1_pipelines, DEV_DATASETS)\n",
    "    loo_l1_results = pd.DataFrame(loo_l1_results)\n",
    "    loo_l1_results[\"i\"] = i\n",
    "    loo_results.append(loo_l1_results)\n",
    "\n",
    "    # All (baseline) LR results\n",
    "    l1_pipelines[i] = {\"AD\": ad_l1_pipelines, \"LOO\": loo_l1_pipelines}\n",
    "    \n",
    "l1_ad_results = pd.concat(ad_results).reset_index(drop=True)\n",
    "l1_ad_results[\"alpha\"] = l1_ad_results[\"model_hparams\"].apply(get_alpha)\n",
    "\n",
    "l1_loo_results = pd.concat(loo_results).reset_index(drop=True)\n",
    "l1_loo_results[\"alpha\"] = l1_loo_results[\"model_hparams\"].apply(get_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fb480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feat_information(pipelines, results, experiment_type, metrics):\n",
    "    results = results.copy()\n",
    "    # For every set of experiments\n",
    "    for i, experiments in pipelines.items():\n",
    "        # Get the experiment_type pipeline (AD or LOO)\n",
    "        for trained_on, pipeline in experiments[experiment_type].items():\n",
    "            # Determine the important features and their importance\n",
    "            _feat_importance = pipeline.model.coef_\n",
    "            _mask = np.abs(_feat_importance) > 1e-6\n",
    "            \n",
    "            trained_on_mask = results[\"trained_on\"] == trained_on\n",
    "            i_mask = results[\"i\"] == i\n",
    "\n",
    "            _feats = np.argsort(np.abs(_feat_importance))[::-1]\n",
    "            _featnames = tuple(metrics[ix] for ix in _feats if _mask[ix])\n",
    "            _feats = {metrics[ix]: _feat_importance[ix] for ix in _feats if _mask[ix]}\n",
    "            _feats[\"intercept_\"] = pipeline.model.intercept_\n",
    "\n",
    "            results.loc[trained_on_mask & i_mask, \"n_features\"] =  sum(_mask)\n",
    "            results.loc[trained_on_mask & i_mask, \"feat_names\"] = str(_featnames)\n",
    "            results.loc[trained_on_mask & i_mask, \"feat_importance\"] = str(_feats)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "l1_ad_results = get_feat_information(l1_pipelines, l1_ad_results, \"AD\", METRICS)\n",
    "l1_ad_results.to_csv(\"results/l1_ad.csv\")\n",
    "\n",
    "l1_loo_results = get_feat_information(l1_pipelines, l1_loo_results, \"LOO\", METRICS)\n",
    "l1_loo_results.to_csv(\"results/l1_loo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204529d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_by_alpha(l1_ad_results, \"mse\")\n",
    "plt.savefig(f\"results/l1_ad_avg_mse_by_alpha{name}.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d929fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_by_alpha(l1_ad_results, \"mse\", hue=\"evaluated_on\")\n",
    "plt.savefig(f\"results/l1_ad_mse_by_alpha_discriminated_by_evaluation_set{name}.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686525c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_by_alpha(l1_loo_results, \"mse\", hue=\"evaluated_on\")\n",
    "plt.savefig(f\"results/l1_loo_mse_by_alpha_discriminated_by_evaluation_set{name}.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79c5ae2",
   "metadata": {},
   "source": [
    "## Random Forest experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df20925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd2d01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All datasets experiment\n",
    "ad_rf_def_pipelines = fit(RandomForestRegressor, {}, METRICS, TARGET, TRAIN_DATASETS)\n",
    "ad_rf_def_results = evaluate(ad_rf_def_pipelines, DEV_DATASETS)\n",
    "ad_rf_def_results = pd.DataFrame(ad_rf_def_results)\n",
    "ad_rf_def_results.to_csv(f\"results/ad_rf{name}.csv\")\n",
    "\n",
    "loo_rf_def_pipelines = fit(RandomForestRegressor, {}, METRICS, TARGET, TRAIN_LOO_DATASETS)\n",
    "loo_rf_def_results = evaluate(loo_rf_def_pipelines, DEV_DATASETS)\n",
    "loo_rf_def_results = pd.DataFrame(loo_rf_def_results)\n",
    "loo_rf_def_results.to_csv(f\"results/loo_rf{name}.csv\")\n",
    "\n",
    "# All (baseline) LR results\n",
    "rf_def_results = pd.concat((ad_rf_def_results, loo_rf_def_results)).reset_index(drop=True)\n",
    "rf_def_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3d7d67",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b329e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "ad_mlp_pipelines1 = fit(MLPRegressor, {\"random_state\": 42, \"early_stopping\": True}, METRICS, TARGET, TRAIN_DATASETS)\n",
    "ad_mlp_results1 = evaluate(ad_mlp_pipelines1, DEV_DATASETS)\n",
    "ad_mlp_results1 = pd.DataFrame(ad_mlp_results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499106c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_mlp_pipelines2 = fit(MLPRegressor, {\"hidden_layer_sizes\": (128, 64, 32), \"random_state\": 42, \"early_stopping\": True}, METRICS, TARGET, TRAIN_DATASETS)\n",
    "ad_mlp_results2 = evaluate(ad_mlp_pipelines2, DEV_DATASETS)\n",
    "ad_mlp_results2 = pd.DataFrame(ad_mlp_results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411b876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_mlp_results = pd.concat((ad_mlp_results1, ad_mlp_results2))\n",
    "ad_mlp_results.to_csv(f\"results/ad_mlp_default{name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1975cd5",
   "metadata": {},
   "source": [
    "## Few shot experiment \n",
    "\n",
    "We can perform this experiment in multiple ways. It considers the LOO experiment. \n",
    "We can use weight the training data differently, and we can use different number of examples in the LOO experiment.\n",
    "\n",
    "For the first experiment, we will consider using all the available training data ($100\\%$) and use different number of points in the LOO. In order to ensure comparable results, we will restrict our _few shot_ examples to the ones available in the training split (that weren't used in the first place) and we evaluate on the same development set. Future experiments may consider enlarging it and using more examples from the dev set.\n",
    "\n",
    "\n",
    "In general, we devise the following steps for a few-shot experiment:\n",
    "1. create dataset of $D_{PT}=(D_1, ..., D_5)$;\n",
    "2. train __model__ $m$ in $D_{PT}$;\n",
    "3. assign weight $w_{PT}$ to examples used in pre-training according to ratio $\\tau$;\n",
    "3. select a fraction of the examples $f$ from $D_6$;\n",
    "4. assign weight $w_{FS}$ to the fraction of $D_6$ examples according to ratio $\\tau$;\n",
    "5. train __model__\n",
    "6. evaluate in dev set for $D_6$\n",
    "5. repeat evaluation for 20 seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b64d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a62648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighting scheme proof of concept\n",
    "n1, n2 = 24_000, 1000\n",
    "n = n1 + n2\n",
    "\n",
    "# If we want n1 examples to be equivalent to a\n",
    "# of the total dataset, then:\n",
    "a = 0.2\n",
    "target_n1, target_n2 = n * a, n * (1-a)\n",
    "n1_w = target_n1 / n1 \n",
    "n2_w = target_n2 / n2\n",
    "print(n1_w, n2_w)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49113ee4",
   "metadata": {},
   "source": [
    "fs_pipeline = FewShotPipeline(\n",
    "    fewshot_dataset=\"cosmosqa\",\n",
    "    fewshot_weight=0.6,\n",
    "    model_class=LinearRegression,\n",
    "    model_hparams={},\n",
    "    dataset=\"except_cosmosqa\",\n",
    "    features=METRICS,\n",
    "    target=TARGET,\n",
    ")\n",
    "\n",
    "fs_pipeline.load_data(TRAIN_LOO_DATASETS[\"except_cosmosqa\"], fewshot_data=TRAIN_DATASETS[\"cosmosqa\"])\n",
    "fs_pipeline.fewshot_fit()\n",
    "# TRAIN_LOO_DATASETS\n",
    "fs_pipeline.evaluate_multiple(DEV_DATASETS);\n",
    "del fs_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc97a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_few_shot_experiment(\n",
    "        train_datasets,\n",
    "        dataset_name,\n",
    "        fewshot_datasets,\n",
    "        fewshot_dataset_name,\n",
    "        eval_datasets,\n",
    "        fewshot_weights,\n",
    "        fewshot_pct_examples,\n",
    "        features,\n",
    "        target,\n",
    "        nruns=5,\n",
    "        seed=81723,\n",
    "        model_class=LinearRegression,\n",
    "        model_hparams={},\n",
    "        pipeline=None,\n",
    "    ):\n",
    "    from itertools import product\n",
    "    rand = np.random.default_rng(seed)\n",
    "    \n",
    "    fewshot_data = fewshot_datasets[fewshot_dataset_name]\n",
    "    \n",
    "    all_results = []\n",
    "    all_pipelines = []\n",
    "    for i, (fewshot_pct, fewshot_weight) in enumerate(product(fewshot_pct_examples, fewshot_weights)):\n",
    "        for j in range(nruns):\n",
    "            seed = rand.integers(10**6)\n",
    "            fewshot_fraction =  fewshot_data.sample(frac=fewshot_pct, replace=False, random_state=seed)\n",
    "            print(len(fewshot_fraction))\n",
    "            # Get subset of few shot data:\n",
    "            if pipeline is None:\n",
    "                pipeline = FewShotPipeline\n",
    "\n",
    "            fs_pipeline = pipeline(\n",
    "                fewshot_dataset=fewshot_dataset_name,\n",
    "                fewshot_weight=fewshot_weight,\n",
    "                model_class=model_class,\n",
    "                model_hparams=model_hparams,\n",
    "                dataset=dataset_name,\n",
    "                features=features,\n",
    "                target=target,\n",
    "                seed=seed,\n",
    "            )\n",
    "\n",
    "            fs_pipeline.load_data(train_datasets[dataset_name], fewshot_data=fewshot_fraction)\n",
    "            fs_pipeline.fewshot_fit()\n",
    "            results = fs_pipeline.evaluate_multiple(eval_datasets)\n",
    "            \n",
    "            for r in results:\n",
    "                r[\"i\"] = i\n",
    "                r[\"seed\"] = seed\n",
    "                r[\"fewshot_weight\"] = fewshot_weight\n",
    "                r[\"fewshot_pct\"] = fewshot_pct\n",
    "                \n",
    "            all_results.extend(results)\n",
    "            all_pipelines.append(fs_pipeline)\n",
    "            \n",
    "    return all_results, all_pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43705a50",
   "metadata": {},
   "source": [
    "### Experiments \n",
    "\n",
    "\n",
    "- [ ] GMMs\n",
    "- [x] Feature engineering: logs\n",
    "- [ ] Ordinal regression\n",
    "- [ ] Create self-contained script to launch fewshot experiment for individual dataset and model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a465826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "RESULTS_DIR = \"results_20220602\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd69c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEWSHOT_PCTS = np.linspace(0.01, 1, 15, endpoint=True)\n",
    "FEWSHOT_WEIGHTS = [0.25, 0.5, 0.75, 0.9, 1, None]\n",
    "\n",
    "print(len(FEWSHOT_PCTS), len(FEWSHOT_WEIGHTS))\n",
    "print(\"Fewshot pcts:\", FEWSHOT_PCTS)\n",
    "print(\"Fewshot weights:\", FEWSHOT_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dad927",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.01"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f832195",
   "metadata": {},
   "source": [
    "config = {\n",
    "    \"model_classpath\": \"sklearn.tree.RandomForestRegressor\",\n",
    "    \"model_hyperparams\": {},\n",
    "    \n",
    "    \"fewshot_pct\": [],\n",
    "    \"fewshot_weights\": [],\n",
    "    \"seed\": \n",
    "    \"nruns\": 1,\n",
    "    \n",
    "    \"training\": {\n",
    "        \"metrics\": METRICS,\n",
    "        \"target\": TARGET,\n",
    "        \"filepath\": ,\n",
    "        \"dataset\": ,\n",
    "    }\n",
    "    \"evaluation\": {\n",
    "        \"filepath\": ,\n",
    "        \"dataset\": ,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da778a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model: \n",
    "    def __init__(self):\n",
    "        self.name = None\n",
    "        self.classpath = None\n",
    "        self.pipeline = None\n",
    "        self.nruns = None\n",
    "\n",
    "model = Model()\n",
    "# model.name, model.classpath, model.hparams, model.nruns = \"lr\", LinearRegression, {}, 10\n",
    "# model.name, model.classpath, model.hparams, model.nruns = \"rf\", RandomForestRegressor, {\"n_jobs\": 15}, 2\n",
    "model.name, model.classpath, model.hparams, model.nruns, model.pipeline = \"mlp\", MLPRegressor, {\"learning_rate\": \"adaptive\", \"random_state\": 42, \"early_stopping\": True}, 5, FineTuningFewShotPipeline\n",
    "\n",
    "USE_LOG_METRICS = False\n",
    "\n",
    "METRICS = [\n",
    "    # Bleu\n",
    "    'bleu1', 'bleu2', 'bleu3', 'bleu4', \n",
    "    # 'hf_bleu1', 'hf_bleu2', 'hf_bleu3', 'hf_bleu4', \n",
    "    'rougeL', \n",
    "    # 'hf_rougeL', 'hf_rougeLsum',\n",
    "    'hf_rouge1', 'hf_rouge2',\n",
    "    'meteor',\n",
    "    'recall', 'precision', 'f1_score',\n",
    "    'sari_context', 'sari_question',\n",
    "    # Token overlap when 1st error occurred\n",
    "    'precision_at_err1', 'recall_at_err1',\n",
    "    # Confusion matrix\n",
    "    'tp', 'fn', 'fp',\n",
    "    # Edit scores ------\n",
    "    'char_edit_score', 'word_edit_score',\n",
    "    # Learned metrics -------\n",
    "    'bertscore', \n",
    "    'bleurt',\n",
    "    \"LERC\",\n",
    "    # Input statistics ------\n",
    "    'candidatelength_word', 'candidatelength_char',\n",
    "    'candidatenunique_words', 'referencelength_word',\n",
    "    'referencelength_char', 'referencenunique_words',\n",
    "    'contextlength_word', 'contextlength_char',\n",
    "    'contextnunique_words', 'questionlength_word',\n",
    "    'questionlength_char', 'questionnunique_words',\n",
    "]\n",
    "\n",
    "if USE_LOG_METRICS and len(LOG_METRICS) > 0:\n",
    "    METRICS += LOG_METRICS_NAMES\n",
    "    model.name += \"_w_log_metrics\"\n",
    "\n",
    "if \"bleurt\" not in METRICS:\n",
    "    model.name += '_no_bleurt'\n",
    "if \"bertscore\" not in METRICS:\n",
    "    model.name += \"_no_bertscore\"\n",
    "if \"LERC\" in METRICS:\n",
    "    model.name += \"_w_LERC\"\n",
    "    \n",
    "print(model.name)\n",
    "DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d9bbbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for dataset in [\"quoref\", \"socialiqa\"]:\n",
    "#for dataset in ['narrativeqa', 'quoref', 'socialiqa']:\n",
    "for dataset in DATASETS:\n",
    "    print(\"Experiment for dataset\", dataset)\n",
    "    loo_fewshot, loo_ps =  run_few_shot_experiment(\n",
    "        train_datasets=TRAIN_LOO_DATASETS,\n",
    "        dataset_name=f\"except_{dataset}\",\n",
    "        fewshot_datasets=TRAIN_DATASETS,\n",
    "        fewshot_dataset_name=dataset,\n",
    "        eval_datasets=DEV_DATASETS,\n",
    "        fewshot_weights=FEWSHOT_WEIGHTS,\n",
    "        fewshot_pct_examples=FEWSHOT_PCTS,\n",
    "        features=METRICS,\n",
    "        target=TARGET,\n",
    "        nruns=model.nruns,\n",
    "        seed=81723,\n",
    "        model_class=model.classpath,\n",
    "        model_hparams=model.hparams,\n",
    "        pipeline=model.pipeline,\n",
    "    )\n",
    "\n",
    "    loo_results = pd.DataFrame(loo_fewshot)\n",
    "    loo_results.fewshot_weight = loo_results.fewshot_weight.fillna(\"default\")\n",
    "    \n",
    "    dataset_dir = f\"{RESULTS_DIR}/{dataset}\"\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    loo_results.to_csv(f\"{dataset_dir}/fewshot_loo_{model.name}_{model.nruns}.csv\")\n",
    "    joblib.dump(loo_ps, f\"{dataset_dir}/fewshot_loo_{model.name}_{model.nruns}.pipelines\")\n",
    "    del loo_fewshot\n",
    "    del loo_ps\n",
    "    del loo_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0278f958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c80b2e871d42739fd0f1d2ac9c8f31a15028627c2324c1cda8de503e9f52a70d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
